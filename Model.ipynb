{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a006625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8fb3f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bf1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=gutenberg.raw('shakespeare-hamlet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d06131",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hamlet.txt', 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0c35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f30cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hamlet.txt', 'r') as f:\n",
    "    text =f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c90c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389a9faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4818"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55e1ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211717b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the---1\n",
      "and---2\n",
      "to---3\n",
      "of---4\n",
      "i---5\n",
      "you---6\n",
      "a---7\n",
      "my---8\n",
      "it---9\n",
      "in---10\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for key,val in (x.items()):\n",
    "    print(f'{key}---{val}')\n",
    "    i+=1\n",
    "    if i==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea07929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input sequences\n",
    "inputsequences=[]\n",
    "for line in text.split('\\n'):\n",
    "    tk_list=tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(tk_list)):\n",
    "        ngram_seq=tk_list[:i+1]\n",
    "        inputsequences.append(ngram_seq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "600714f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25732"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdd21d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len=max([len(x) for x in inputsequences])\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "574e4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsequences=np.array(pad_sequences(inputsequences,maxlen=max_seq_len,padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4002b24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    1,  687],\n",
       "       [   0,    0,    0, ...,    1,  687,    4],\n",
       "       [   0,    0,    0, ...,  687,    4,   45],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4,   45, 1047],\n",
       "       [   0,    0,    0, ...,   45, 1047,    4],\n",
       "       [   0,    0,    0, ..., 1047,    4,  193]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16c04ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=extract all rows and and coloumns except the last coloumn\n",
    "# y=extract the last coloumn in every row\n",
    "import tensorflow as tf\n",
    "x,y=inputsequences[:,:-1], inputsequences[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4dd0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=tf.keras.utils.to_categorical(y,num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc228df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cda63ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adc4f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56027a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential([\n",
    "    Embedding(total_words,100,input_length=max_seq_len-1),\n",
    "    LSTM(150,return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dense(total_words,activation='softmax')\n",
    "])\n",
    "\n",
    "#Embedding(input_dim, output_dim, input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d47187b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f0b717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 13, 100)           481800    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 13, 150)           150600    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 13, 150)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4818)              486618    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,219,418\n",
      "Trainable params: 1,219,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01b3fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "644/644 [==============================] - 7s 10ms/step - loss: 2.5906 - accuracy: 0.4340 - val_loss: 11.4453 - val_accuracy: 0.0523\n",
      "Epoch 2/100\n",
      "644/644 [==============================] - 7s 10ms/step - loss: 2.5558 - accuracy: 0.4375 - val_loss: 11.4962 - val_accuracy: 0.0567\n",
      "Epoch 3/100\n",
      "644/644 [==============================] - 7s 11ms/step - loss: 2.5239 - accuracy: 0.4434 - val_loss: 11.5250 - val_accuracy: 0.0528\n",
      "Epoch 4/100\n",
      "644/644 [==============================] - 7s 11ms/step - loss: 2.4954 - accuracy: 0.4471 - val_loss: 11.5843 - val_accuracy: 0.0528\n",
      "Epoch 5/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.4613 - accuracy: 0.4557 - val_loss: 11.6793 - val_accuracy: 0.0538\n",
      "Epoch 6/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 2.4380 - accuracy: 0.4581 - val_loss: 11.7654 - val_accuracy: 0.0540\n",
      "Epoch 7/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.4057 - accuracy: 0.4680 - val_loss: 11.8118 - val_accuracy: 0.0540\n",
      "Epoch 8/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.3710 - accuracy: 0.4727 - val_loss: 11.8631 - val_accuracy: 0.0517\n",
      "Epoch 9/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.3470 - accuracy: 0.4758 - val_loss: 11.9280 - val_accuracy: 0.0542\n",
      "Epoch 10/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.3213 - accuracy: 0.4829 - val_loss: 11.9926 - val_accuracy: 0.0536\n",
      "Epoch 11/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.2937 - accuracy: 0.4866 - val_loss: 12.0266 - val_accuracy: 0.0558\n",
      "Epoch 12/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.2637 - accuracy: 0.4952 - val_loss: 12.0916 - val_accuracy: 0.0530\n",
      "Epoch 13/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.2368 - accuracy: 0.4982 - val_loss: 12.1653 - val_accuracy: 0.0505\n",
      "Epoch 14/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.2158 - accuracy: 0.5037 - val_loss: 12.2147 - val_accuracy: 0.0521\n",
      "Epoch 15/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.1848 - accuracy: 0.5119 - val_loss: 12.2823 - val_accuracy: 0.0519\n",
      "Epoch 16/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.1648 - accuracy: 0.5150 - val_loss: 12.3066 - val_accuracy: 0.0530\n",
      "Epoch 17/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 2.1393 - accuracy: 0.5212 - val_loss: 12.3875 - val_accuracy: 0.0552\n",
      "Epoch 18/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.1143 - accuracy: 0.5259 - val_loss: 12.4623 - val_accuracy: 0.0548\n",
      "Epoch 19/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 2.0873 - accuracy: 0.5300 - val_loss: 12.4651 - val_accuracy: 0.0476\n",
      "Epoch 20/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 2.0700 - accuracy: 0.5345 - val_loss: 12.5508 - val_accuracy: 0.0501\n",
      "Epoch 21/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 2.0460 - accuracy: 0.5382 - val_loss: 12.5719 - val_accuracy: 0.0505\n",
      "Epoch 22/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 2.0228 - accuracy: 0.5432 - val_loss: 12.6442 - val_accuracy: 0.0521\n",
      "Epoch 23/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.9993 - accuracy: 0.5461 - val_loss: 12.6796 - val_accuracy: 0.0492\n",
      "Epoch 24/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.9775 - accuracy: 0.5525 - val_loss: 12.7447 - val_accuracy: 0.0527\n",
      "Epoch 25/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.9574 - accuracy: 0.5555 - val_loss: 12.7939 - val_accuracy: 0.0511\n",
      "Epoch 26/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.9435 - accuracy: 0.5627 - val_loss: 12.8730 - val_accuracy: 0.0482\n",
      "Epoch 27/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.9128 - accuracy: 0.5671 - val_loss: 12.9642 - val_accuracy: 0.0495\n",
      "Epoch 28/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.8988 - accuracy: 0.5699 - val_loss: 12.9475 - val_accuracy: 0.0505\n",
      "Epoch 29/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.8689 - accuracy: 0.5729 - val_loss: 13.0434 - val_accuracy: 0.0499\n",
      "Epoch 30/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.8602 - accuracy: 0.5794 - val_loss: 13.0750 - val_accuracy: 0.0517\n",
      "Epoch 31/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.8377 - accuracy: 0.5832 - val_loss: 13.1079 - val_accuracy: 0.0519\n",
      "Epoch 32/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.8172 - accuracy: 0.5868 - val_loss: 13.1413 - val_accuracy: 0.0503\n",
      "Epoch 33/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.8037 - accuracy: 0.5871 - val_loss: 13.2084 - val_accuracy: 0.0501\n",
      "Epoch 34/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.7758 - accuracy: 0.5976 - val_loss: 13.1970 - val_accuracy: 0.0525\n",
      "Epoch 35/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.7584 - accuracy: 0.5974 - val_loss: 13.3235 - val_accuracy: 0.0515\n",
      "Epoch 36/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.7468 - accuracy: 0.6000 - val_loss: 13.3245 - val_accuracy: 0.0497\n",
      "Epoch 37/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.7257 - accuracy: 0.6024 - val_loss: 13.3981 - val_accuracy: 0.0507\n",
      "Epoch 38/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.7130 - accuracy: 0.6075 - val_loss: 13.4097 - val_accuracy: 0.0511\n",
      "Epoch 39/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.6909 - accuracy: 0.6118 - val_loss: 13.4940 - val_accuracy: 0.0519\n",
      "Epoch 40/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.6744 - accuracy: 0.6172 - val_loss: 13.5364 - val_accuracy: 0.0528\n",
      "Epoch 41/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.6581 - accuracy: 0.6197 - val_loss: 13.5607 - val_accuracy: 0.0493\n",
      "Epoch 42/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.6436 - accuracy: 0.6208 - val_loss: 13.5835 - val_accuracy: 0.0527\n",
      "Epoch 43/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.6266 - accuracy: 0.6269 - val_loss: 13.6537 - val_accuracy: 0.0511\n",
      "Epoch 44/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.6113 - accuracy: 0.6282 - val_loss: 13.6619 - val_accuracy: 0.0495\n",
      "Epoch 45/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.6012 - accuracy: 0.6311 - val_loss: 13.7399 - val_accuracy: 0.0517\n",
      "Epoch 46/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.5791 - accuracy: 0.6392 - val_loss: 13.7497 - val_accuracy: 0.0511\n",
      "Epoch 47/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.5679 - accuracy: 0.6369 - val_loss: 13.7819 - val_accuracy: 0.0515\n",
      "Epoch 48/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.5503 - accuracy: 0.6393 - val_loss: 13.8696 - val_accuracy: 0.0515\n",
      "Epoch 49/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.5364 - accuracy: 0.6422 - val_loss: 13.9441 - val_accuracy: 0.0509\n",
      "Epoch 50/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.5219 - accuracy: 0.6491 - val_loss: 13.9967 - val_accuracy: 0.0509\n",
      "Epoch 51/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.5156 - accuracy: 0.6486 - val_loss: 13.9968 - val_accuracy: 0.0495\n",
      "Epoch 52/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.5028 - accuracy: 0.6534 - val_loss: 14.0233 - val_accuracy: 0.0468\n",
      "Epoch 53/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.4867 - accuracy: 0.6590 - val_loss: 14.0318 - val_accuracy: 0.0497\n",
      "Epoch 54/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.4755 - accuracy: 0.6604 - val_loss: 14.1084 - val_accuracy: 0.0476\n",
      "Epoch 55/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.4578 - accuracy: 0.6606 - val_loss: 14.1156 - val_accuracy: 0.0503\n",
      "Epoch 56/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.4449 - accuracy: 0.6634 - val_loss: 14.1610 - val_accuracy: 0.0507\n",
      "Epoch 57/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.4297 - accuracy: 0.6691 - val_loss: 14.1755 - val_accuracy: 0.0482\n",
      "Epoch 58/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.4125 - accuracy: 0.6695 - val_loss: 14.2581 - val_accuracy: 0.0501\n",
      "Epoch 59/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.4149 - accuracy: 0.6700 - val_loss: 14.3075 - val_accuracy: 0.0490\n",
      "Epoch 60/100\n",
      "644/644 [==============================] - 7s 10ms/step - loss: 1.3962 - accuracy: 0.6746 - val_loss: 14.3867 - val_accuracy: 0.0523\n",
      "Epoch 61/100\n",
      "644/644 [==============================] - 7s 11ms/step - loss: 1.3853 - accuracy: 0.6788 - val_loss: 14.3776 - val_accuracy: 0.0519\n",
      "Epoch 62/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.3776 - accuracy: 0.6763 - val_loss: 14.3863 - val_accuracy: 0.0501\n",
      "Epoch 63/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.3589 - accuracy: 0.6849 - val_loss: 14.4587 - val_accuracy: 0.0513\n",
      "Epoch 64/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.3483 - accuracy: 0.6836 - val_loss: 14.5088 - val_accuracy: 0.0505\n",
      "Epoch 65/100\n",
      "644/644 [==============================] - 7s 10ms/step - loss: 1.3472 - accuracy: 0.6855 - val_loss: 14.5697 - val_accuracy: 0.0482\n",
      "Epoch 66/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.3290 - accuracy: 0.6879 - val_loss: 14.5506 - val_accuracy: 0.0492\n",
      "Epoch 67/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.3208 - accuracy: 0.6909 - val_loss: 14.5944 - val_accuracy: 0.0480\n",
      "Epoch 68/100\n",
      "644/644 [==============================] - 7s 10ms/step - loss: 1.3064 - accuracy: 0.6959 - val_loss: 14.6157 - val_accuracy: 0.0462\n",
      "Epoch 69/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.3027 - accuracy: 0.6961 - val_loss: 14.6878 - val_accuracy: 0.0482\n",
      "Epoch 70/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.2894 - accuracy: 0.6965 - val_loss: 14.7030 - val_accuracy: 0.0488\n",
      "Epoch 71/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.2748 - accuracy: 0.7008 - val_loss: 14.7334 - val_accuracy: 0.0499\n",
      "Epoch 72/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.2689 - accuracy: 0.7009 - val_loss: 14.7752 - val_accuracy: 0.0488\n",
      "Epoch 73/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.2612 - accuracy: 0.7033 - val_loss: 14.8585 - val_accuracy: 0.0492\n",
      "Epoch 74/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.2509 - accuracy: 0.7084 - val_loss: 14.8413 - val_accuracy: 0.0482\n",
      "Epoch 75/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.2400 - accuracy: 0.7093 - val_loss: 14.9137 - val_accuracy: 0.0521\n",
      "Epoch 76/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.2291 - accuracy: 0.7128 - val_loss: 14.9713 - val_accuracy: 0.0493\n",
      "Epoch 77/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.2302 - accuracy: 0.7111 - val_loss: 14.9503 - val_accuracy: 0.0478\n",
      "Epoch 78/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.2141 - accuracy: 0.7158 - val_loss: 14.9882 - val_accuracy: 0.0493\n",
      "Epoch 79/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.2039 - accuracy: 0.7181 - val_loss: 15.0280 - val_accuracy: 0.0482\n",
      "Epoch 80/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1956 - accuracy: 0.7197 - val_loss: 15.0679 - val_accuracy: 0.0460\n",
      "Epoch 81/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.1908 - accuracy: 0.7174 - val_loss: 15.0942 - val_accuracy: 0.0470\n",
      "Epoch 82/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1799 - accuracy: 0.7220 - val_loss: 15.1220 - val_accuracy: 0.0493\n",
      "Epoch 83/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1694 - accuracy: 0.7217 - val_loss: 15.1774 - val_accuracy: 0.0505\n",
      "Epoch 84/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1652 - accuracy: 0.7226 - val_loss: 15.2170 - val_accuracy: 0.0466\n",
      "Epoch 85/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1627 - accuracy: 0.7239 - val_loss: 15.2866 - val_accuracy: 0.0484\n",
      "Epoch 86/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1385 - accuracy: 0.7324 - val_loss: 15.2710 - val_accuracy: 0.0459\n",
      "Epoch 87/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1386 - accuracy: 0.7307 - val_loss: 15.2903 - val_accuracy: 0.0449\n",
      "Epoch 88/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.1321 - accuracy: 0.7341 - val_loss: 15.3430 - val_accuracy: 0.0486\n",
      "Epoch 89/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1389 - accuracy: 0.7299 - val_loss: 15.3751 - val_accuracy: 0.0462\n",
      "Epoch 90/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1179 - accuracy: 0.7361 - val_loss: 15.3823 - val_accuracy: 0.0474\n",
      "Epoch 91/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1134 - accuracy: 0.7355 - val_loss: 15.4272 - val_accuracy: 0.0501\n",
      "Epoch 92/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.1038 - accuracy: 0.7368 - val_loss: 15.4624 - val_accuracy: 0.0501\n",
      "Epoch 93/100\n",
      "644/644 [==============================] - 6s 10ms/step - loss: 1.0948 - accuracy: 0.7412 - val_loss: 15.5060 - val_accuracy: 0.0470\n",
      "Epoch 94/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.0947 - accuracy: 0.7405 - val_loss: 15.5141 - val_accuracy: 0.0478\n",
      "Epoch 95/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.0871 - accuracy: 0.7402 - val_loss: 15.5507 - val_accuracy: 0.0501\n",
      "Epoch 96/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.0759 - accuracy: 0.7439 - val_loss: 15.5853 - val_accuracy: 0.0462\n",
      "Epoch 97/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.0730 - accuracy: 0.7440 - val_loss: 15.6309 - val_accuracy: 0.0492\n",
      "Epoch 98/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.0741 - accuracy: 0.7427 - val_loss: 15.6377 - val_accuracy: 0.0488\n",
      "Epoch 99/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.0547 - accuracy: 0.7476 - val_loss: 15.6728 - val_accuracy: 0.0480\n",
      "Epoch 100/100\n",
      "644/644 [==============================] - 6s 9ms/step - loss: 1.0479 - accuracy: 0.7530 - val_loss: 15.7404 - val_accuracy: 0.0476\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(xtrain,ytrain,epochs=100,validation_data=(xtest,ytest), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a89d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the next word\n",
    "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    if len(token_list) >= max_sequence_len:\n",
    "        token_list = token_list[-(max_sequence_len-1):]  # Ensure the sequence length matches max_sequence_len-1\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ce67f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:This Spirit dumbe to vs, will speake to\n",
      "Next Word Prediction:him\n"
     ]
    }
   ],
   "source": [
    "input_text=\"This Spirit dumbe to vs, will speake to\"\n",
    "print(f\"Input text:{input_text}\")\n",
    "max_sequence_len=model.input_shape[1]+1\n",
    "next_word=predict_next_word(model,tokenizer,input_text,max_sequence_len)\n",
    "print(f\"Next Word Prediction:{next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a604973",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "## Save the tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f256e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
